# Project 5: Real-Time RAG Assistant

A real-time conversational AI assistant with **streaming responses** (SSE), **conversation memory**, and **live knowledge ingestion** â€” powered by PostgreSQL + pgvector and NVIDIA LLM APIs.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Browser (UI)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Sidebar   â”‚    â”‚   Chat Panel        â”‚    â”‚ Knowledge     â”‚  â”‚
â”‚  â”‚ Convos    â”‚    â”‚   SSE streaming     â”‚    â”‚ Base Panel    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ HTTP + SSE
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Backend                              â”‚
â”‚                                                                 â”‚
â”‚  POST /chat                                                     â”‚
â”‚    â”‚                                                            â”‚
â”‚    â”œâ”€ 1. Save user message                                      â”‚
â”‚    â”œâ”€ 2. Load conversation history (last 5 msgs)                â”‚
â”‚    â”œâ”€ 3. Generate query embedding â”€â”€â”€â”€â”€â”€â–º NVIDIA Embeddings API â”‚
â”‚    â”œâ”€ 4. Vector similarity search â”€â”€â”€â”€â”€â”€â–º pgvector (PostgreSQL) â”‚
â”‚    â”œâ”€ 5. Build augmented prompt with context                    â”‚
â”‚    â””â”€ 6. Stream response via SSE â”€â”€â”€â”€â”€â”€â”€â–º NVIDIA Chat API       â”‚
â”‚         (token by token)                   (stream: true)       â”‚
â”‚                                                                 â”‚
â”‚  POST /knowledge                                                â”‚
â”‚    â”œâ”€ Accept text or URL (auto-scrape)                          â”‚
â”‚    â”œâ”€ Generate embedding                                        â”‚
â”‚    â””â”€ Store in pgvector                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL + pgvector                         â”‚
â”‚                                                                 â”‚
â”‚  rt_knowledge       â”‚ rt_conversations  â”‚ rt_messages            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚  id, title,         â”‚ id, created_at    â”‚ id, conversation_id,  â”‚
â”‚  content, source,   â”‚                   â”‚ role, content,        â”‚
â”‚  embedding(1024)    â”‚                   â”‚ chunks_used, time     â”‚
â”‚  HNSW index         â”‚                   â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

```
User types question
       â”‚
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Query   â”‚â”€â”€â”€â”€â–ºâ”‚  Embed query â”‚â”€â”€â”€â”€â–ºâ”‚  pgvector   â”‚
  â”‚  text    â”‚     â”‚  (NVIDIA)    â”‚     â”‚  cosine     â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  search     â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚ top-K chunks
                                               â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   Conversation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Build prompt:   â”‚
   history (5 msgs)                 â”‚  system + context â”‚
                                    â”‚  + history + msg  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  NVIDIA Chat API â”‚
                                    â”‚  stream: true    â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚ tokens
                                             â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  SSE stream      â”‚
                                    â”‚  data: {token}   â”‚â”€â”€â”€â”€â”€â”€â–º Browser
                                    â”‚  event: done     â”‚        (real-time)
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Features

- **ğŸ”„ Real-time streaming** â€” Responses appear token-by-token via Server-Sent Events
- **ğŸ’¬ Conversation memory** â€” Chat history persisted in PostgreSQL, last 5 messages used as context
- **ğŸ“š Live knowledge ingestion** â€” Add text or URLs to the knowledge base in real-time
- **ğŸ” Semantic search** â€” pgvector HNSW index for fast cosine similarity retrieval
- **ğŸ¨ Modern dark UI** â€” ChatGPT-style interface with sidebar, chat bubbles, and knowledge panel

## Tech Stack

| Component | Technology |
|-----------|-----------|
| Backend | FastAPI (Python) |
| Database | PostgreSQL 17 + pgvector |
| Embeddings | NVIDIA `nv-embedqa-e5-v5` (1024 dims) |
| LLM | `moonshotai/kimi-k2.5` via NVIDIA API |
| Streaming | Server-Sent Events (SSE) |
| Frontend | Vanilla HTML/CSS/JS |

## Setup

```bash
cd projects/rag-portfolio/05-realtime-assistant

# Activate venv
source ../venv/bin/activate

# Seed the database with example articles
python seed.py

# Run the server
python app.py
# â†’ http://localhost:8005
```

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/` | Web UI |
| `POST` | `/knowledge` | Add knowledge (text or URL) |
| `GET` | `/knowledge` | List all knowledge items |
| `DELETE` | `/knowledge/{id}` | Remove knowledge item |
| `POST` | `/conversations` | Create new conversation |
| `GET` | `/conversations` | List all conversations |
| `GET` | `/conversations/{id}/messages` | Get conversation messages |
| `POST` | `/chat` | Send message â†’ stream response (SSE) |

### Chat request example

```bash
curl -N -X POST http://localhost:8005/chat \
  -H "Content-Type: application/json" \
  -d '{"conversation_id": 1, "message": "What is RAG?"}'
```

Response stream:
```
event: search
data: [{"id": 3, "title": "RAG", "similarity": 0.92}]

data: {"token": "RAG"}
data: {"token": " stands"}
data: {"token": " for"}
...
event: done
data: {}
```

## SSE vs WebSocket

This project uses **SSE** (Server-Sent Events) instead of WebSocket because:

1. **Simpler** â€” Unidirectional (server â†’ client), standard HTTP
2. **Native support** â€” Browser `fetch` + `ReadableStream` handles it
3. **Auto-reconnect** â€” Built into the EventSource API
4. **Sufficient** â€” LLM streaming is inherently unidirectional
5. **FastAPI native** â€” `StreamingResponse` works out of the box

## Database Schema

Tables are prefixed with `rt_` (real-time):

- **`rt_knowledge`** â€” Knowledge base with vector embeddings (HNSW indexed)
- **`rt_conversations`** â€” Conversation sessions
- **`rt_messages`** â€” Chat messages with role, content, and used chunks metadata
